<!DOCTYPE html>
<meta charset="utf-8" />
<title>Streams Standard</title>
<style>
  span.minor {
    letter-spacing: 0;
    color: black;
    font-size: 0.8em;
    font-weight: normal;
  }
</style>

<link href="http://www.whatwg.org/style/specification" rel="stylesheet" />

<div class="head">
  <h1>Streams</h1>

  <h2 class="no-num no-toc">
    <span class="minor">[soon to become a]</span> Living Standard — Last Updated [DATE: 01 Jan 1901]
  </h2>

  <dl>
    <dt>Participate:</dt>
    <dd>
      Send feedback to
      <a href="http://www.whatwg.org/mailing-list">whatwg@whatwg.org</a>
      (<a href="http://www.whatwg.org/mailing-list#specs">archives</a>) or
      <a href="https://github.com/whatwg/streams/issues/new">file a bug</a>
      (<a href="https://github.com/whatwg/streams/issues?state=open">open bugs</a>)
    </dd>
    <dd><a href="http://wiki.whatwg.org/wiki/IRC">IRC: #whatwg on Freenode</a></dd>

    <dt>Version History:</dt>
    <dd><a href="https://github.com/whatwg/streams/commits">https://github.com/whatwg/streams/commits</a></dd>

    <dt>Editor:</dt>
    <dd class="h-card vcard"><a class="u-url url p-name fn" href="http://domenic.me/">Domenic Denicola</a>
    &lt;<a class="u-email email" href="mailto:domenic@domenicdenicola.com">domenic@domenicdenicola.com</a>&gt;
  </dl>

  <p class="copyright">
    <a href="http://creativecommons.org/publicdomain/zero/1.0/" rel="license"><img src="http://i.creativecommons.org/p/zero/1.0/80x15.png" alt="CC0"></a>

    To the extent possible under law, the editor has waived all copyright and related or neighboring rights to this
    work.
  </p>
</div>

<h2 class="no-num no-toc">Table of Contents</h2>
<!--toc-->

<h2 class="no-num no-toc">Abstract</h2>

<p>This specification provides APIs for creating, composing, and consuming streams of data. These streams are designed
to map efficiently to low-level I/O primitives, and allow easy composition with built-in backpressure and buffering. On
top of streams, the web platform can build higher-level abstractions, such as filesystem or socket APIs, while at the
same time users can use the supplied tools to build their own streams which integrate well with those of the web
platform.</p>

<h2 class="no-num no-toc">Status</h2>

<p>This specification is in the process of establishing itself in the WHATWG. As such, the term "Living Standard"
indicates a goal, rather than reality.</p>

<p>Although the core algorithms and APIs are largely present and working, prototyping and testing of them is still
underway, and there is still room for additional APIs beyond those specified here. Please join us in the
<a href="https://github.com/whatwg/streams/issues?state=open">issue tracker</a> for more discussion.</p>

<h2>Conformance</h2>

<p>All diagrams, examples, and notes in this specification are non-normative, as are all sections explicitly marked
non-normative. Everything else in this specification is normative.</p>

<p>The key words "MUST", "MUST NOT", "REQUIRED", <!--"SHALL", "SHALL NOT",--> "SHOULD", "SHOULD NOT", "RECOMMENDED",
"MAY", and "OPTIONAL" in the normative parts of this specification are to be interpreted as described in RFC2119. For
readability, these words do not appear in all uppercase letters in this specification.
<span data-anolis-ref>RFC2119</span></p>

<p>Conformance requirements phrased as algorithms or specific steps may be implemented in any manner, so long as the end
result is equivalent.</p>

<h2>Model</h2>

<h3>Readable Streams</h3>

<p>A <dfn>readable stream</dfn> represents a source of data, from which you can read. In other words, data comes
<em>out</em> of a readable stream.</p>

<p>Although a readable stream can be created with arbitrary behavior, most readable streams wrap a lower-level I/O
source, called the <dfn>underlying source</dfn>. There are two types of underlying source: push sources and pull
sources.</p>

<p><dfn>Push sources</dfn> push data at you, whether or not you are listening for it. They may also provide a mechanism
for pausing and resuming the flow of data. An example push source is a TCP socket, where data is constantly being pushed
from the OS level, at a rate that can be controlled by changing the TCP window size.</p>

<p><dfn>Pull sources</dfn> require you to request data from them. The data may be available synchronously, e.g. if it is
held by the operating system's in-memory buffers, or asynchronously, e.g. if it has to be read from disk. An example
pull source is a file handle, where you seek to specific locations and read specific amounts.</p>

<p>Readable streams are designed to wrap both types of sources behind a single, unified interface.</p>

<h3>Writable Streams</h3>

<p>A <dfn>writable stream</dfn> represents a destination for data, into which you can write. In other words, data goes
<em>in</em> to a writable stream.</p>

<p>Analogously to readable streams, most writable streams wrap a lower-level I/O sink, called the <dfn>underlying
sink</dfn>. Writable streams work to abstract away some of the complexity of the underlying sink, by buffering
subsequent writes and only delivering them to the underlying sink one by one.</p>

<h3>Transform Streams</h3>

<p>A <dfn>transform stream</dfn> consists of a pair of streams: a writable stream input, and a readable stream output.
In a manner specific to the transform stream in question, writes to the input side result in new data being made
available for reading from the output side.</p>

<p>Some examples of transform streams include:</p>

<ul>
  <li>A text decoder, which takes as input bytes and produces as output strings;</li>
  <li>A GZIP compressor, which takes as input uncompressed bytes and produces as output compressed bytes;</li>
  <li>A video decoder, which takes as input encoded bytes and produces as output uncompressed video frames.</li>
</ul>

<h3>Pipe Chains and Backpressure</h3>

<p>Streams are primarily used by <dfn>piping</dfn> them to each other. A readable stream can be piped directly to a
writable stream, or it can be piped through one or more transform streams first.</p>

<p>A set of streams piped together in this way is referred to as a <dfn>pipe chain</dfn>. In a pipe chain, the
<dfn>ultimate producer</dfn> is the first readable stream in the chain; the <dfn>ultimate consumer</dfn> is the final
writable stream in the chain.</p>

<p>Once a pipe chain is constructed, it can be used to propagate signals regarding how fast data should flow through
it. If any step in the chain cannot yet accept data, it propagates a signal backwards through the pipe chain, until
eventually the ultimate producer is told to stop producing data so fast. This process of normalizing data flow from the
ultimate producer according to how fast the chain can process data is called <dfn>backpressure</dfn>.</p>

<h2>Readable Streams</h2>

<h3>Introduction to Readable Streams</h3>

<p><em>This section is non-normative.</em></p>

<p>The readable stream API allows wrapping both pull and push sources into a single <code>ReadableStream</code>
abstraction. To accomplish this, the API uses the
<a href="http://domenic.me/2014/02/14/the-revealing-constructor-pattern/">revealing constructor pattern</a>. The
constructor of a given stream instance is supplied with two functions, <code>start</code> and <code>pull</code>, which
each are given the parameters <code>(push, close, error)</code> representing capabilities tied to the internals of the
stream. By mediating all access to the internal state machine through these three functions, the stream's internal
state and bookkeeping can be kept private, allowing nobody but the original producer of the stream to insert data into
it.</p>

<p>This specification provides both a lower-level <code>BaseReadableStream</code> class, and a higher-level
<code>ReadableStream</code> class. <code>ReadableStream</code> layers on top of <code>BaseReadableStream</code> the
ability to customize the stream's buffering strategy, which impacts backpressure; it also supports piping the stream
to or through multiple destinations.</p>

<div class="example">
  <p>The following function wraps a push source, represented by a "raw socket," which triggers events for data, end,
  and error, and provides the ability to pause and resume the flow of data.</p>

<pre><code>function makeSocketStream(host, port, { highWaterMark = 16 * 1024 } = {}) {
  const rawSocket = createRawSocketObject(host, port);

  return new ReadableStream({
    start(push, close, error) {
      // When adapting a push source, usually most of the work happens in start.

      rawSocket.ondata = chunk => {
        if (!push(chunk)) {
          // If push returns false, the internal buffer is full, so propagate
          // the backpressure signal to the underlying source.
          rawSocket.readStop();
        }
      };

      rawSocket.onend = close;

      rawSocket.onerror = error;
    },

    pull() {
      // This is called if the internal buffer has been emptied, but the
      // stream's consumer still wants more data.
      rawSocket.readStart();
    },

    cancel() {
      // If the stream is prematurely canceled, release resources.
      rawSocket.readStop();
      rawSocket = null;
    },

    strategy: new LengthBufferingStrategy({ highWaterMark })
  });
}</code></pre>

  <p>We can then use this function to create readable streams for sockets, and pipe those streams to arbitrary writable
  streams:</p>

<pre><code>var socketStream = makeSocketStream("http://example.com", 80);

socketStream.pipeTo(writableStream).closed
  .then(() => console.log("All data successfully written!"))
  .catch(e => console.error("Something went wrong!", e));</code></pre>
</div>

<div class="example">
  <p>The following function wraps a pull source, represented by a "raw file handle," which provides methods for opening,
  reading from, and closing itself. These methods can call their callbacks either synchronously or asynchronously—a
  <a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Zalgo-releasing</a> horror which we can
  hide from our users by wrapping them in a readable stream.</p>

<pre><code>function makeReadableFileStream(filename, { highWaterMark = 16 * 1024 } = {}) {
  const fileHandle = createRawFileHandle(filename, "r");

  return new ReadableStream({
    start() {
      return new Promise((resolve, reject) => {
        fileHandle.open(err => {
          if (err) {
            reject(err);
          }
          resolve();
        });
      });
    },

    pull(push, close, error) {
      // When adapting a pull source, usually most of the work happens in pull.

      fileHandle.read((err, isDone, data) => {
        if (err) {
          // If trying to read data results in an error, report that.
          error(err);
        } else if (isDone) {
          // If there's no more data to read, be sure to close the underlying
          // source, ensuring that it succeeds before reporting success.
          fileHandle.close(err => {
            if (err) {
              error(err);
            }
            close();
          });
        } else {
          // If data was read successfully, push it into the internal buffer.
          push(data);
        }
      });
    },

    cancel() {
      // If the stream canceled prematurely, release resources.
      fileHandle.close();
      fileHandle = null;
    },

    strategy: new LengthBufferingStrategy({ highWaterMark })
  });
}</code></pre>

  <p>We can then create and use readable streams for files just as we could before for sockets.</p>
</div>

<div class="example">
  <p>Although readable streams will usually be used by piping them to a writable stream, you can also "pump" them
  directly, alternating between using the <code>read()</code> and <code>wait()</code> methods according to the current
  value of the <code>state</code> property. For example, this function writes the contents of a readable stream to the
  console as fast as they are available.</p>

<pre><code>function streamToConsole(readableStream) {
  pump();

  function pump() {
    while (readableStream.state === "readable") {
      console.log(readableStream.read());
    }

    if (readableStream.state === "closed") {
      console.log("--- all done!");
    } else {
      // If we're in an error state, the returned promise will be rejected with
      // that error, so no need to handle "waiting" vs. "errored" separately.
      readableStream.wait().then(pump, e => console.error(e));
    }
  }
}</code></pre>
</div>

<h3>The Readable Stream State Diagram</h3>

<p><em>This section is non-normative.</em></p>

<p>As evidenced by the above explanations, readable streams have a fairly complex internal state machine, which is responsible for keeping track of the internal buffer, and initiating appropriate actions in response to calls to a stream's methods. This can be roughly summarized in the following diagram.</p>

<figure>
  <img src="readable-stream.svg" width="578" alt="The readable stream state machine diagram." />

  <figcaption>
    <dl>
      <dt><span style="font-style: normal; font-weight: normal; font-family: monospace;">monospace</span></dt>
      <dd>Methods of the stream</dd>

      <dt><span style="font-style: normal; font-weight: bold;">bold</span></dt>
      <dd>Constructor parameters</dd>

      <dt><span style="font-style: italic; font-weight: normal;">italic</span></dt>
      <dd>Capabilities given to constructor parameters</dd>
    </dl>
  </figcaption>
</figure>


<h3>Class <code>BaseReadableStream</code></h3>

<h3>Class <code>ReadableStream</code></h3>

<h2>Writable Streams</h2>

<h3>Introduction to Writable Streams</h3>

<p><em>This section is non-normative.</em></p>

<p>The writable stream API allows wrapping of underlying sinks into an object on which two fundamental operations can
be performed: data can be written to the stream, and the stream can be closed.</p>

<p>The writable stream implementation is designed to encapsulate the potential complexity of the underlying sink from
users of the stream API. In particular, users of a stream object can write data to the stream at any pace, without
regard for whether previous writes have completed or succeeded. It is the job of the stream implementation to ensure
that writes are forwarded to the underlying sink in order, and only after successful completion of previous writes.
This allows seamless use of the writable stream even in cases such as piping a fast readable file stream to a slower
writable network socket stream, which cannot acknowledge the incoming data at the same rate it becomes available.</p>

<p>This specification provides both a lower-level <code>BaseWritableStream</code> class, and a higher-level
<code>WritableStream</code> class. <code>WritableStream</code> layers on top of <code>BaseWritableStream</code> the
ability to customize the stream's buffering strategy, which can be communicated backward in a pipe chain to cause
backpressure.</p>

<div class="example">
  <p>The following function wraps an underlying sink, represented as a "raw file handle," which provides methods for
  opening, writing to, and closing itself. These methods can call their callbacks either synchronously or
  asynchronously—a <a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Zalgo-releasing</a>
  horror which we can hide from our users by wrapping them in a writable stream.</p>

<pre><code>function makeWritableFileStream(filename, { highWaterMark = 16 * 1024 } = {}) {
  const fileHandle = createRawFileHandle(filename, "w");

  return new WritableStream({
    start() {
      return new Promise((resolve, reject) => {
        fileHandle.open(err => {
          if (err) {
            reject(err);
          }
          resolve();
        });
      });
    },

    write(data, done, error) {
      fileHandle.write(data, writeErr => {
        if (writeErr) {
          // If trying to write results in an error, (attempt to) close the
          // underlying file handle; we're not going to write any more.
          fileHandle.close(closeErr => {
            // If *closing* errors, pass along that error to the stream.
            if (closeErr) {
              error(closeErr);
            }

            // Otherwise, if closing succeeds, pass along the write error.
            error(writeErr);
          });
        } else {
          // If there's no error, then signal that this write completed.
          done();
        }
      });
    },

    close() {
      return new Promise((resolve, reject) => {
        fileHandle.close(err => {
          if (err) {
            reject(err);
          }
          resolve();
        });
      });
    },

    abort() {
      // If the stream aborted prematurely, release resources.
      fileHandle.close();
      fileHandle = null;
    },

    strategy: new LengthBufferingStrategy({ highWaterMark })
  });
}</code></pre>

  <p>We can then use this function to create a writable stream for a file, and then pipe a readable stream to it:</p>

<pre><code>var fileStream = makeWritableFileStream("/example/path/on/fs.txt");

readableStream.pipeTo(fileStream).closed
  .then(() => console.log("All data successfully written!"))
  .catch(e => console.error("Something went wrong!", e));</code></pre>

  <p>Note that if a particular call to <code>fileHandle.write</code> takes a longer time, <code>done</code> will be
  called later. In the meantime, additional writes can be queued up, which are stored in the stream's internal buffer.
  The accumulation of this buffer can move the stream into a <code>"waiting"</code> state, which is a signal to users
  of the stream that they should back off and stop writing if possible.</p>
</div>

<div class="example">
  <p>Although writable streams will usually be used by piping to them from a readable stream, you can also write to them
  directly. Since they buffer any incoming writes, and take care internally to forward them to the underlying sink
  in sequence, you can indiscriminately write to a writable stream without much ceremony:</p>

<pre><code>function writeArrayToStream(array, writableStream) {
  array.forEach(chunk => writableStream.write(chunk));

  return writableStream.close();
}

writeArrayToStream([1, 2, 3, 4, 5], writableStream)
  .then(() => console.log("All done!"))
  .catch(e => console.error("Error with the stream: " + e));</code></pre>
</div>

<h3>The Writable Stream State Diagram</h3>

<p><em>This section is non-normative.</em></p>

<h3>Class <code>BaseWritableStream</code></h3>

<h3>Class <code>WritableStream</code></h3>

<h2>Subclassing Streams</h2>

<p><em>This section is non-normative.</em></p>

<p>Although functional by themselves for most cases, <code>ReadableStream</code>, <code>WritableStream</code>, and
others can also be subclassed to provide additional functionality. Subclasses will generally fall into one of two
camps:</p>

<ul>
  <li>Additive subclasses, adding new APIs onto the stream instances. An example would be a file stream that includes
  <code>filename</code> or other filesystem-related properties, or a HTTP response stream that includes header-accessing
  APIs.</li>
  <li>Override subclasses, which change the behavior of the stream's methods fundamentally. An example would be a
  readable TCP stream that overrides <code>read</code>, <code>wait</code>, <code>cancel</code>, <code>state</code>, and
  <code>closed</code> to reflect and manipulate a kernel-level TCP buffer.</li>
</ul>

<p>On an implementation level, additive subclasses will usually call <code>super</code> in their constructor,
initializing their base class's internal buffer and accessing it through the provided parameters to their
superconstructor. Whereas override subclasses will simply reimplement the appropriate methods directly, forgoing a call
to <code>super</code> and all the internal state that comes with it. They will then provide a new constructor, which
does not pass the usual capability-accessing parameters to consumers.</p>

<p>Because streams only interact through their public API, both types of stream subclasses can coexist. For example, you
can pipe to or from a subclassed stream of either sort, without worrying what type of implementation is under the
covers, as long as the appropriate properties and methods are provided.</p>

<p>Finally, note that subclassing is rarely <em>necessary</em> for implementing custom streams. Instead, you can simply
describe how to create a stream that wraps some underlying source or sink by describing constructor parameters that do
so, and that use the passed capabilities to forward the relevant data and state transitions to the stream's existing
representations. This approach has the advantage of alleviating you of having to manually implement many of the complex
requirements baked into the stream state machines and the contract they present to users.</p>

<h2>Other Stream APIs</h2>

<h3><code>TeeStream</code></h3>

<h3><code>LengthBufferingStrategy</code></h3>

<h3><code>CountBufferingStrategy</code></h3>

<h2 class="no-num">Acknowledgments</h2>

<p>The editor would like to thank
Bert Belder,
Marcos Caceres,
Tim Caswell,
Forbes Lindesay,
Thorsten Lorenz,
Jens Nockert,
Trevor Norris,
Dominic Tarr,
Takeshi Yoshino, and
tzik
for their contributions to this specification.</p>

<p>Special thanks to:
Gorgi Kosev for his breakthrough idea of separating piping into two methods, thus resolving
  <a href="https://github.com/whatwg/streams/issues/44">a major sticking point</a>;
Forrest Norvell for his enthusiastic iteration on the reference implementation;
Isaac Schlueter for his pioneering work on JavaScript streams in Node.js; and
Jake Verbaten for his continued involvement, support, and interest in pushing this spec forward.
</p>

<script id="head" src="http://www.whatwg.org/specs/web-apps/current-work/dfn.js"></script>
