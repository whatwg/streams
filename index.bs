<!DOCTYPE html>
<meta charset="utf-8" />
<title>Streams Standard</title>
<style>
  span.minor {
    letter-spacing: 0;
    color: black;
    font-size: 0.8em;
    font-weight: normal;
  }

  /* Compensate for Bikeshed omitting spaces, unlike Anolis which other specs use */
  .toc .secno::after {
    content: ' ';
  }
</style>

<link rel="stylesheet" href="//www.whatwg.org/style/specification" />
<link rel="icon" href="//resources.whatwg.org/logo-streams.svg" />

<pre class="metadata">
  Shortname: streams
  Level: 1
  Status: DREAM
  ED: https://whatwg.github.io/streams
  Editor: Domenic Denicola, Google, http://domenic.me
  Abstract: Don't wanna exceed 120 chars, so I put it below instead.
</pre>

<div class="head">
  <a class="logo" href="//www.whatwg.org/">
    <img alt="WHATWG" src="//resources.whatwg.org/logo-streams.svg" width="100" height="100">
  </a>

  <hgroup>
    <h1>Streams</h1>

    <h2 id="subtitle" class="no-num no-toc">
      <span class="minor">[soon to become a]</span> Living Standard; Last Updated [DATE]
    </h2>
  </hgroup>

  <dl>
    <dt>Participate:</dt>
    <dd>
      Send feedback to
      <a href="http://www.whatwg.org/mailing-list">whatwg@whatwg.org</a>
      (<a href="http://www.whatwg.org/mailing-list#specs">archives</a>) or
      <a href="https://github.com/whatwg/streams/issues/new">file a bug</a>
      (<a href="https://github.com/whatwg/streams/issues?state=open">open bugs</a>)
    </dd>
    <dd><a href="http://wiki.whatwg.org/wiki/IRC">IRC: #whatwg on Freenode</a></dd>

    <dt>Version History:</dt>
    <dd><a href="https://github.com/whatwg/streams/commits">https://github.com/whatwg/streams/commits</a></dd>

    <dt>Editor:</dt>
    <dd class="h-card vcard">
      <a href="http://domenic.me/">Domenic Denicola</a>
      (<a href="https://google.com/">Google</a>)
      &lt;<a href="mailto:domenic@domenicdenicola.com">domenic@domenicdenicola.com</a>&gt;
    </dd>
  </dl>

  <p class="copyright">
    <a href="http://creativecommons.org/publicdomain/zero/1.0/" rel="license">
      <img src="http://i.creativecommons.org/p/zero/1.0/80x15.png" alt="CC0">
    </a>
    To the extent possible under law, the editor has waived all copyright and related or neighboring rights to this
    work. In addition, as of [DATE], the editor has made this specification available under the
    <a href="http://www.openwebfoundation.org/legal/the-owf-1-0-agreements/owfa-1-0" rel="license">Open Web Foundation
    Agreement Version 1.0</a>, which is available at http://www.openwebfoundation.org/legal/the-owf-1-0-agreements/owfa-1-0.
  </p>
</div>

<h2 id="abstract" class="no-num no-toc">Abstract</h2>

This specification provides APIs for creating, composing, and consuming streams of data. These streams are designed
to map efficiently to low-level I/O primitives, and allow easy composition with built-in backpressure and queuing. On
top of streams, the web platform can build higher-level abstractions, such as filesystem or socket APIs, while at the
same time users can use the supplied tools to build their own streams which integrate well with those of the web
platform.

<h2 id="status" class="no-num no-toc">Status</h2>

This specification is in the process of establishing itself in the WHATWG. As such, the term "Living Standard"
indicates a goal, rather than reality.

Although the core algorithms and APIs are largely present and working, prototyping and testing of them is still
underway, and there is still room for additional APIs beyond those specified here. Please join us in the
<a href="https://github.com/whatwg/streams/issues?state=open">issue tracker</a> for more discussion.

<h2 id="toc" class="no-num no-toc">Table of Contents</h2>
<div data-fill-with="table-of-contents"></div>

<h2 id="model">Model</h2>

A <dfn>chunk</dfn> is a single piece of data that is written to or read from a stream. It can be of any type; streams
can even contain chunks of different types. A chunk will often not be the most atomic unit of data for a given stream;
for example a binary stream might contain chunks consisting of 16 KiB <code>ArrayBuffer</code>s, instead of single
bytes.

<h3 id="rs-model">Readable Streams</h3>

A <dfn>readable stream</dfn> represents a source of data, from which you can read. In other words, data comes
<em>out</em> of a readable stream.

Although a readable stream can be created with arbitrary behavior, most readable streams wrap a lower-level I/O source,
called the <dfn>underlying source</dfn>. There are two types of underlying source: push sources and pull sources.

<dfn title="push source">Push sources</dfn> push data at you, whether or not you are listening for it. They may also provide a mechanism
for pausing and resuming the flow of data. An example push source is a TCP socket, where data is constantly being pushed
from the OS level, at a rate that can be controlled by changing the TCP window size.

<dfn title="pull source">Pull sources</dfn> require you to request data from them. The data may be available synchronously, e.g. if it is
held by the operating system's in-memory buffers, or asynchronously, e.g. if it has to be read from disk. An example
pull source is a file handle, where you seek to specific locations and read specific amounts.

Readable streams are designed to wrap both types of sources behind a single, unified interface.

<a>Chunks</a> are enqueued into the stream by the stream's creator, who usually derives them from the <a>underlying
source</a>. They can then be read one at a time via the stream's public interface.

<h3 id="ws-model">Writable Streams</h3>

A <dfn>writable stream</dfn> represents a destination for data, into which you can write. In other words, data goes
<em>in</em> to a writable stream.

Analogously to readable streams, most writable streams wrap a lower-level I/O sink, called the
<dfn>underlying sink</dfn>. Writable streams work to abstract away some of the complexity of the underlying sink, by
queuing subsequent writes and only delivering them to the underlying sink one by one.

<a>Chunks</a> are enqueued into the stream via its public interface, and are passed one at a time to the stream's
creator. In turn, the creator will usually forward them to the <a>underlying sink</a>.

<h3 id="ts-model">Transform Streams</h3>

A <dfn>transform stream</dfn> consists of a pair of streams: a writable stream input, and a readable stream output.
In a manner specific to the transform stream in question, writes to the input side result in new data being made
available for reading from the output side.

Some examples of transform streams include:

<ul>
  <li>A text decoder, which takes as input bytes and produces as output strings;</li>
  <li>A GZIP compressor, which takes as input uncompressed bytes and produces as output compressed bytes;</li>
  <li>A video decoder, which takes as input encoded bytes and produces as output uncompressed video frames.</li>
</ul>

<h3 id="pipe-chains">Pipe Chains and Backpressure</h3>

Streams are primarily used by <dfn>piping</dfn> them to each other. A readable stream can be piped directly to a
writable stream, or it can be piped through one or more transform streams first.

A set of streams piped together in this way is referred to as a <dfn>pipe chain</dfn>. In a pipe chain, the
<dfn>ultimate producer</dfn> is the first readable stream in the chain; the <dfn>ultimate consumer</dfn> is the final
writable stream in the chain.

Once a pipe chain is constructed, it can be used to propagate signals regarding how fast data should flow through
it. If any step in the chain cannot yet accept data, it propagates a signal backwards through the pipe chain, until
eventually the ultimate producer is told to stop producing data so fast. This process of normalizing data flow from the
ultimate producer according to how fast the chain can process data is called <dfn>backpressure</dfn>.

<h2 id="rs">Readable Streams</h2>

<h3 id="rs-intro">Introduction to Readable Streams</h3>

<em>This section is non-normative.</em>

The readable stream API allows wrapping both pull and push sources into a single <code>ReadableStream</code>
abstraction. To accomplish this, the API uses the
<a href="http://domenic.me/2014/02/14/the-revealing-constructor-pattern/">revealing constructor pattern</a>. The
constructor of a given stream instance is supplied with two functions, <code>start</code> and <code>pull</code>, which
each are given the parameters <code>(enqueue, close, error)</code> representing capabilities tied to the internals of the
stream. By mediating all access to the internal state machine through these three functions, the stream's internal
state and bookkeeping can be kept private, allowing nobody but the original producer of the stream to insert data into
it.

<div class="example">
  The following function creates readable streams that wrap web sockets [[HTML]], which are push sources that do not
  support backpressure signals.

  <pre>
    function makeReadableWebSocketStream(url, protocols) {
      const ws = new WebSocket(url, protocols);
      ws.binaryType = "arraybuffer";

      return new ReadableStream({
        start(enqueue, close, error) {
          // When adapting a push source, usually most of the work happens in start.

          ws.onmessage = event => enqueue(event.data);
          ws.onend = close;
          ws.onerror = error;
        },

        cancel() {
          ws.close();
        }
      });
    }
  </pre>

  We can then use this function to create readable streams for web sockets, and pipe those streams to arbitrary
  writable streams:

  <pre>
    var webSocketStream = makeReadableWebSocketStream("http://example.com", 80);

    socketStream.pipeTo(writableStream).closed
      .then(() => console.log("All data successfully written!"))
      .catch(e => console.error("Something went wrong!", e));
  </pre>
</div>

<div class="example">
  The following function wraps a push source, represented by a hypothetical "raw socket" interface, which triggers
  events for data, end, and error (much like a web socket), but also provides the ability to pause and resume the flow
  of data. Thus, this example shows how to apply backpressure to <a>underlying sources</a> that support it.

  <pre>
    function makeSocketStream(host, port) {
      const rawSocket = createRawSocketObject(host, port);

      return new ReadableStream({
        start(enqueue, close, error) {
          rawSocket.ondata = event => {
            if (!enqueue(event.data)) {
              // If enqueue returns false, the internal queue is full, so propagate
              // the backpressure signal to the underlying source.
              rawSocket.readStop();
            }
          };

          rawSocket.onend = close;
          rawSocket.onerror = error;
        },

        pull() {
          // This is called if the internal queue has been emptied, but the
          // stream's consumer still wants more data. In that case, restart
          // the flow of data if we have previously paused it.
          rawSocket.readStart();
        },

        cancel() {
          rawSocket.readStop();
        }
      });
    }
  </pre>

  We can then use this function to create readable streams for such "raw sockets" in the same way we do for web
  sockets. This time, however, when we pipe to a destination that cannot accept data as fast as the socket is producing
  it, a backpressure signal will be sent to the raw socket.
</div>

<div class="example">
  The following function wraps a pull source, represented by a "raw file handle," which provides methods for opening,
  reading from, and closing itself. These methods can call their callbacks either synchronously or asynchronously—a
  <a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Zalgo-releasing</a> horror which we can
  hide from our users by wrapping them in a readable stream.

  <pre>
    function makeReadableFileStream(filename) {
      const fileHandle = createRawFileHandle(filename, "r");

      return new ReadableStream({
        start() {
          return new Promise((resolve, reject) => {
            fileHandle.open(err => {
              if (err) {
                reject(err);
              }
              resolve();
            });
          });
        },

        pull(enqueue, close, error) {
          // When adapting a pull source, usually most of the work happens in pull.

          fileHandle.read((err, isDone, chunk) => {
            if (err) {
              // If trying to read data results in an error, report that.
              error(err);
            } else if (isDone) {
              // If there's no more data to read, be sure to close the underlying
              // source, ensuring that it succeeds before reporting success.
              fileHandle.close(err => {
                if (err) {
                  error(err);
                }
                close();
              });
            } else {
              // If data was read successfully, enqueue it into the internal queue.
              enqueue(chunk);
            }
          });
        },

        cancel() {
          fileHandle.close();
        }
      });
    }
  </pre>

  We can then create and use readable streams for files just as we could before for sockets.
</div>

<div class="example">
  Although readable streams will usually be used by piping them to a writable stream, you can also "pump" them
  directly, alternating between using the <code>read()</code> and <code>wait()</code> methods according to the current
  value of the <code>state</code> property. For example, this function writes the contents of a readable stream to the
  console as fast as they are available.

  <pre>
    function streamToConsole(readableStream) {
      pump();

      function pump() {
        while (readableStream.state === "readable") {
          console.log(readableStream.read());
        }

        if (readableStream.state === "closed") {
          console.log("--- all done!");
        } else {
          // If we're in an error state, the returned promise will be rejected with
          // that error, so no need to handle "waiting" vs. "errored" separately.
          readableStream.wait().then(pump, e => console.error(e));
        }
      }
    }
  </pre>
</div>

<h3 id="rs-state-diagram">The Readable Stream State Diagram</h3>

<em>This section is non-normative.</em>

As evidenced by the above explanations, readable streams have a fairly complex internal state machine, which is
responsible for keeping track of the internal queue, and initiating appropriate actions in response to calls to a
stream's methods. This can be roughly summarized in the following diagram.

<figure>
  <img src="readable-stream.svg" width="578" alt="The readable stream state machine diagram." />

  <figcaption>
    <dl>
      <dt><span style="font-style: normal; font-weight: normal; font-family: monospace;">monospace</span></dt>
      <dd>Methods of the stream</dd>

      <dt><span style="font-style: normal; font-weight: bold;">bold</span></dt>
      <dd>Constructor parameters</dd>

      <dt><span style="font-style: italic; font-weight: normal;">italic</span></dt>
      <dd>Capabilities given to constructor parameters</dd>
    </dl>
  </figcaption>
</figure>


<h3 id="rs-class">Class <code>ReadableStream</code></h3>

<h2 id="ws">Writable Streams</h2>

<h3 id="ws-intro">Introduction to Writable Streams</h3>

<em>This section is non-normative.</em>

The writable stream API allows wrapping of <a>underlying sinks</a> into an object on which two fundamental operations
can be performed: data can be written to the stream, and the stream can be closed.

The writable stream implementation is designed to encapsulate the potential complexity of the <a>underlying sink</a>
from users of the stream API. In particular, users of a stream object can write data to the stream at any pace, without
regard for whether previous writes have completed or succeeded. It is the job of the stream implementation to ensure
that writes are forwarded to the <a>underlying sink</a> in order, and only after successful completion of previous writes.
This allows seamless use of the writable stream even in cases such as piping a fast readable file stream to a slower
writable network socket stream, which cannot acknowledge the incoming data at the same rate it becomes available.

<div class="example">
  The following function wraps a web socket [[HTML]] as the <a>underlying sink</a> of a new writable stream. Web
  sockets do not provide any way to tell when a given chunk of data has been successfully sent, so this writable stream
  has no ability to communicate backpressure signals to any users: it will always be in the <code>"writable"</code>
  state.

  <pre>
    function makeWritableWebSocketStream(url, protocols) {
      const ws = new WebSocket(url, protocols);

      return new WritableStream({
        start() {
          return new Promise((resolve, reject) => {
            ws.onopen = resolve;
            ws.onerror = reject;
          });
        },

        write(chunk, done, error) {
          ws.onerror = error;
          ws.send(chunk);

          // Call done() immediately since the web socket gives us no way to tell
          // when the write completes.
          done();
        },

        close() {
          return new Promise((resolve, reject) => {
            ws.onclose = resolve;
            ws.onerror = error;
            ws.close();
          });
        }
      });
    }
  </pre>
</div>

<div class="example">
  The following function wraps an <a>underlying sink</a>, represented as a hypothetical "raw file handle," which
  provides methods for opening, writing to, and closing itself. Notably, the raw file handle's <code>write</code> method
  calls back to signal when writes are complete, which allows the stream to correctly communicate backpressure signals
  to any users by setting its state to <code>"waiting"</code> instead of <code>"writable"</code> when the queue gets too
  full. Allow of the raw file handle's methods can call their callbacks either synchronously or asynchronously—a
  <a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Zalgo-releasing</a> horror which we can
  hide from our users by wrapping them in a writable stream.

  <pre>
    function makeWritableFileStream(filename) {
      const fileHandle = createRawFileHandle(filename, "w");

      return new WritableStream({
        start() {
          return new Promise((resolve, reject) => {
            fileHandle.open(err => {
              if (err) {
                reject(err);
              }
              resolve();
            });
          });
        },

        write(chunk, done, error) {
          fileHandle.write(chunk, writeErr => {
            if (writeErr) {
              // If trying to write results in an error, (attempt to) close the
              // underlying file handle; we're not going to write any more.
              fileHandle.close(closeErr => {
                // If *closing* errors, pass along that error to the stream.
                if (closeErr) {
                  error(closeErr);
                }

                // Otherwise, if closing succeeds, pass along the write error.
                error(writeErr);
              });
            } else {
              // If there's no error, then signal that this write completed.
              done();
            }
          });
        },

        close() {
          return new Promise((resolve, reject) => {
            fileHandle.close(err => {
              if (err) {
                reject(err);
              }
              resolve();
            });
          });
        }
      });
    }
  </pre>

  We can then use this function to create a writable stream for a file, and then pipe a readable stream to it:

  <pre>
    var fileStream = makeWritableFileStream("/example/path/on/fs.txt");

    readableStream.pipeTo(fileStream).closed
      .then(() => console.log("All data successfully written!"))
      .catch(e => console.error("Something went wrong!", e));
  </pre>

  Note that if a particular call to <code>fileHandle.write</code> takes a longer time, <code>done</code> will be
  called later. In the meantime, additional writes can be queued up, which are stored in the stream's internal queue.
  The accumulation of this queue can move the stream into a <code>"waiting"</code> state, which is a signal to users
  of the stream that they should back off and stop writing if possible.
</div>

<div class="example">
  Although writable streams will usually be used by piping to them from a readable stream, you can also write to them
  directly. Since they queue any incoming writes, and take care internally to forward them to the <a>underlying sink</a>
  in sequence, you can indiscriminately write to a writable stream without much ceremony:

  <pre>
    function writeArrayToStream(array, writableStream) {
      array.forEach(chunk => writableStream.write(chunk));

      return writableStream.close();
    }

    writeArrayToStream([1, 2, 3, 4, 5], writableStream)
      .then(() => console.log("All done!"))
      .catch(e => console.error("Error with the stream: " + e));
  </pre>
</div>

<h3 id="ws-state-diagram">The Writable Stream State Diagram</h3>

<em>This section is non-normative.</em>

TODO

<h3 id="ws-class">Class <code>WritableStream</code></h3>

<h2 id="subclassing">Subclassing Streams</h2>

<em>This section is non-normative.</em>

Specific APIs may wish to subclass <code>ReadableStream</code> or <code>WritableStream</code> in order to provide
additional functionality. Examples would include:

<ul>
  <li>A file stream that is constructed from a filename, and includes file metadata</li>
  <li>A HTTP stream that is constructed from a URL, and includes header-accessing APIs</li>
  <li>A TCP stream that overrides <code>read</code>, <code>wait</code>, <code>cancel</code>, <code>state</code>, and
  <code>closed</code> to reflect and manipulate a kernel-level TCP buffer</li>
</ul>

The first two examples here could be expressed by allowing their constructors to call <code>super</code> with
appropriate functions that manipulate the stream's internal state. The latter takes a different approach, which gives
both more power and more responsibility: it requires that the author of that stream manually implement many of the
complex requirements baked into the readable stream state machine and the contract it presents to users.

Because streams only interact through their public API, all streams—whether subclassed or not—can coexist and
interoperate. For example, you can pipe to or from any of the above streams, without worrying what type of
implementation is under the covers, since they all provide the appropriate properties and methods.

<h2 id="other-apis">Other Stream APIs</h2>

<h3 id="tee-stream"><code>TeeStream</code></h3>

<h3 id="ByteLengthQueuingStrategy"><code>ByteLengthQueuingStrategy</code></h3>

<h3 id="CountQueuingStrategy"><code>CountQueuingStrategy</code></h3>

<h2 id="acks" class="no-num">Acknowledgments</h2>

The editor would like to thank
Bert Belder,
Marcos Caceres,
Tim Caswell,
Forbes Lindesay,
Thorsten Lorenz,
Jens Nockert,
Trevor Norris,
Dominic Tarr, and
tzik
for their contributions to this specification.

Special thanks to:
Gorgi Kosev for his breakthrough idea of separating piping into two methods, thus resolving
  <a href="https://github.com/whatwg/streams/issues/44">a major sticking point</a>;
Forrest Norvell for his enthusiastic iteration on the reference implementation;
Isaac Schlueter for his pioneering work on JavaScript streams in Node.js;
Jake Verbaten for his continued involvement, support, and interest in pushing this spec forward; and
Takeshi Yoshino for his careful review of this spec's algorithms and concepts.


<h2 id="conformance" class="no-num no-ref">Conformance</h2>

All diagrams, examples, and notes in this specification are non-normative, as are all sections explicitly marked
non-normative. Everything else in this specification is normative.

The key words "MUST", "MUST NOT", "REQUIRED", <!--"SHALL", "SHALL NOT",--> "SHOULD", "SHOULD NOT", "RECOMMENDED",
"MAY", and "OPTIONAL" in the normative parts of this specification are to be interpreted as described in RFC2119. For
readability, these words do not appear in all uppercase letters in this specification. [[!RFC2119]]

Conformance requirements phrased as algorithms or specific steps may be implemented in any manner, so long as the end
result is equivalent.

<h2 id="references" class="no-num no-ref">References</h2>

<h3 id="normative" class="no-num no-ref">Normative References</h3>
<div data-fill-with="normative-references"></div>

<h3 id="informative" class="no-num no-ref">Informative References</h3>
<div data-fill-with="informative-references"></div>

<h2 id="index" class="no-num no-ref">Index</h2>
<div data-fill-with="index"></div>
